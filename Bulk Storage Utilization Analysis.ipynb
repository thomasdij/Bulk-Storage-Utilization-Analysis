{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44c21b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import count\n",
    "from re import L\n",
    "from turtle import left, right\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openpyxl as op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "167d7735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "bulk_list_df = pd.read_excel('Bulk Location Dimensions 5-5-22.xlsx', sheet_name='Bulk Locs inches')\n",
    "full_df = pd.read_excel('Product_By_Location_Report 4-22-22.xlsx', sheet_name='Report 1', skiprows=7)\n",
    "stack_df = pd.read_excel('Stacking Allowances 4-25-22.xlsx', sheet_name='Max Stack List', skiprows=1)\n",
    "article_master_df = pd.read_excel('SPWR_ArticleMaster_(KF)_and_PackStructure_(PD)_Report.xlsx',\n",
    "                                  sheet_name='SPWR Article Master')\n",
    "# drop empty columns created by cells unmerged in Excel and other unused columns\n",
    "full_df = full_df.drop(\n",
    "    ['Unnamed: 0', 'Depot Code', 'Unnamed: 3', 'Unnamed: 14', 'Unnamed: 16', 'Article Ref 3', \n",
    "     'Article Date 1', 'Article Date 2', ], axis=1)\n",
    "# numbers come formatted with commas which needs to be cleaned to allow for numerical operations\n",
    "full_df = full_df.replace(',', '', regex=True)\n",
    "article_master_df = article_master_df.replace(',', '', regex=True)\n",
    "bulk_list_df = bulk_list_df.replace(',', '', regex=True)\n",
    "stack_df = stack_df.replace(',', '', regex=True)\n",
    "# remove trailing and leading spaces from applicable data so that identical values between tables \n",
    "# can be recognized\n",
    "bulk_list_df['Whse Location'] = bulk_list_df['Whse Location'].str.strip()\n",
    "full_df['Whse Location'] = full_df['Whse Location'].str.strip()\n",
    "full_df['Article ID'] = full_df['Article ID'].str.strip()\n",
    "article_master_df['Article ID'] = article_master_df['Article ID'].str.strip()\n",
    "stack_df['Article ID'] = stack_df['Article ID'].str.strip()\n",
    "# create dataframe bulk_df as subset of full_df containing only bulk locations\n",
    "bulk_df = full_df\n",
    "bulk_df = bulk_df.merge(bulk_list_df, how='right', on='Whse Location')\n",
    "bulk_df = bulk_df.sort_values('Whse Location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df33790d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find volume utilization in bulk area\n",
    "def find_bulk_utilization():\n",
    "    bulk_volume_used = bulk_df['Case Volume Actual'].sum()\n",
    "    # bulk_list has units in inches, convert to ft by dividing by 1728 in3/ft3 to match bulk_volume_used\n",
    "    bulk_volume_available = bulk_list_df['Avail Volume (in3)'].sum() / 1728\n",
    "    bulk_utilization = bulk_volume_used / bulk_volume_available\n",
    "    print(\"Bulk Utiliztion\", round((100 * bulk_utilization), 2), \"%\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d3d312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create partially filled loc report\n",
    "# create column with qty of each item in each loc\n",
    "count_df = bulk_df\n",
    "count_df['Count'] = 0\n",
    "count_df = count_df.groupby(['Whse Location']).Count.count().reset_index()\n",
    "count_df = count_df.drop_duplicates(subset=['Whse Location'])\n",
    "bulk_df = bulk_df.drop_duplicates(subset=['Whse Location'])\n",
    "bulk_df = bulk_df.reset_index()\n",
    "count_df = count_df.reset_index()\n",
    "bulk_df = bulk_df.merge(count_df, how='left', on='Whse Location')\n",
    "bulk_df = bulk_df.drop(['index_x', 'Count_x', 'Whse Zone_y', 'index_y'], axis=1)\n",
    "bulk_df = bulk_df.rename(columns={'Whse Zone_x': 'Whse Zone', 'Count_y': 'Qty in Loc'})\n",
    "bulk_df = bulk_df.sort_values('Whse Location')\n",
    "\n",
    "# add product dimensions\n",
    "bulk_article_df = article_master_df[\n",
    "    ['Article ID', 'Article Description', 'PL Length', 'PL Width', 'PL Height', 'PL Volume']]\n",
    "bulk_df = bulk_df.merge(bulk_article_df, how='left', on='Article ID')\n",
    "# create column for maximum number of items that can fit within each location\n",
    "# still need to add rounding up all columns with number of columns as zero to 1\n",
    "bulk_df['Max Columns of Item'] = (bulk_df['Avail Width (in)'] / (bulk_df['PL Width'] * 12)).apply(np.floor)\n",
    "bulk_df['Max Columns of Item'].replace(0, 1)\n",
    "bulk_df['Max Rows of Item'] = (bulk_df['Avail Depth  (in)'] / (bulk_df['PL Length'] * 12)).apply(np.floor)\n",
    "bulk_df = bulk_df.merge(stack_df, how='left', on='Article ID')\n",
    "# bulk_df['Max Stacks of Item'] = (bulk_df['Avail Height (in)']/(bulk_df['PL Height']*12)).apply(np.floor) bulk_df[\n",
    "# 'Max Stacks of Item'] = bulk_df['Article ID'].apply(lambda x: (bulk_df['Avail Height (in)']/(bulk_df['PL\n",
    "# Height']*12)).apply(np.floor) if bulk_df['Article ID'].str.contains('PV', case=False, regex=True) else 1) create\n",
    "# column for number of additional items that could be added to each location\n",
    "bulk_df['Max Item Qty'] = bulk_df['Max Columns of Item'] * bulk_df['Max Rows of Item'] * bulk_df['Max Stack']\n",
    "bulk_df['Fillable Item Qty'] = bulk_df['Max Item Qty'] - bulk_df['Qty in Loc']\n",
    "# restructure dataframe to be easier to read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333e5713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export partially filled loc report\n",
    "bulk_df.to_csv(r'C:\\Python Apps\\Space Utilization\\Bulk App\\Output Files\\Test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
